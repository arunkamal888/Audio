import numpy as np
import scipy.io.wavfile as wav
import matplotlib.pyplot as plt
from moviepy.editor import VideoFileClip
import speech_recognition as sr

def extract_audio_from_video(mp4_file, output_audio_file):
    """Extracts the audio from an MP4 file and saves it as a .wav file."""
    video = VideoFileClip(mp4_file)
    video.audio.write_audiofile(output_audio_file)
    print(f"Audio extracted to: {output_audio_file}")

def analyze_audio_properties(data, sample_rate):
    """Analyze properties like duration, RMS, and channels."""
    duration = len(data) / sample_rate  # in seconds
    channels = data.shape[1] if len(data.shape) > 1 else 1  # Check if stereo or mono

    # Calculate RMS (Root Mean Square)
    rms = np.sqrt(np.mean(data**2))

    return duration, channels, rms

def detect_silence(data, threshold=0.01):
    """Detect silence in audio data."""
    silence_detected = np.mean(np.abs(data)) < threshold
    silence_percentage = np.mean(np.abs(data) < threshold)  # Calculate percentage of silence
    return silence_detected, silence_percentage

def calculate_snr(signal, noise):
    """Calculate Signal-to-Noise Ratio (SNR)."""
    signal_power = np.mean(signal ** 2)
    noise_power = np.mean(noise ** 2)
    snr = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else float('inf')
    return snr

def detect_glitches(data, threshold=0.9):
    """Detect glitches by checking for abnormal spikes in the waveform."""
    glitches = np.where(np.abs(data) > threshold * np.max(np.abs(data)))[0]
    return glitches

def detect_clipping(data, threshold=1.0):
    """Detect if audio has been clipped (amplitude exceeds max value)."""
    clipping = np.any(np.abs(data) >= threshold)
    return clipping

def detect_frequency_spikes(data, sample_rate, threshold=1000):
    """Detect spikes in the frequency domain using FFT."""
    freq_data = np.fft.rfft(data)
    freqs = np.fft.rfftfreq(len(data), d=1/sample_rate)
    spikes = np.where(np.abs(freq_data) > threshold)[0]
    return len(spikes)

def plot_waveform(data, sample_rate, duration, channels, rms, silence_percentage, snr, glitches, clipping, freq_spikes, output_file):
    """Plot the audio waveform with analysis information and save as PNG."""
    
    time = np.linspace(0., duration, num=len(data))  # Time axis based on sample rate and duration
    
    # Set up the figure
    plt.figure(figsize=(14, 8))
    
    # Plot waveform
    plt.subplot(2, 1, 1)  # First plot (waveform) in a 2-row grid
    plt.plot(time, data, label='Waveform', color='b')
    plt.title('Audio Waveform with Quality Analysis')
    plt.xlabel('Time [s]')
    plt.ylabel('Amplitude')
    plt.axhline(0, color='grey', linestyle='--')  # Zero amplitude line
    plt.legend()
    plt.grid()

    # Annotate audio quality metrics
    plt.subplot(2, 1, 2)  # Second plot (quality report) in the 2-row grid
    metrics = [
        f"Duration: {duration:.2f} seconds",
        f"Channels: {channels}",
        f"RMS: {rms:.5f}",
        f"Silence Detected: {'Yes' if silence_percentage > 0.2 else 'No'} ({silence_percentage:.2%})",
        f"SNR: {snr:.2f} dB",
        f"Glitches Detected: {len(glitches)}",
        f"Clipping Detected: {'Yes' if clipping else 'No'}",
        f"Frequency Spikes: {freq_spikes}"
    ]
    
    # Plotting the metrics on the second subplot
    plt.text(0.5, 0.8, "\n".join(metrics), fontsize=12, verticalalignment='center', horizontalalignment='center')
    plt.axis('off')  # Turn off the axis since we're just displaying text

    # Save the plot as an image
    plt.tight_layout()
    plt.savefig(output_file)
    plt.close()  # Close the figure to free up memory

def transcribe_audio(audio_file):
    """Recognizes speech from the given audio file using Google's Speech Recognition API."""
    recognizer = sr.Recognizer()
    with sr.AudioFile(audio_file) as source:
        audio_data = recognizer.record(source)
        try:
            print("Performing speech recognition...")
            text = recognizer.recognize_google(audio_data)
            return text
        except sr.UnknownValueError:
            print("Speech recognition could not understand the audio")
            return ""
        except sr.RequestError:
            print("Could not request results from Google Speech Recognition service")
            return ""

def rate_audio_quality(file_path):
    """Rate the audio quality based on various metrics."""
    # Load audio file directly within this function
    sample_rate, data = wav.read(file_path)

    # Analyze audio properties
    duration, channels, rms = analyze_audio_properties(data, sample_rate)

    # Detect silence
    silence_detected, silence_percentage = detect_silence(data)

    # Calculate SNR
    if len(data) > 1000:  # To avoid index errors
        snr = calculate_snr(data[:len(data)//10], data[len(data)//10:len(data)//5])
    else:
        snr = 0

    # Detect glitches
    glitches = detect_glitches(data)

    # Detect clipping
    clipping = detect_clipping(data)

    # Detect frequency spikes
    freq_spikes = detect_frequency_spikes(data, sample_rate)

    # Print report
    print(f"Audio Quality Report for: {file_path}")
    print(f"Duration: {duration:.2f} seconds")
    print(f"Channels: {channels}")
    print(f"RMS: {rms:.5f}")
    print(f"Silence Detected: {'Yes' if silence_detected else 'No'} ({silence_percentage:.2%})")
    print(f"SNR: {snr:.2f} dB")
    print(f"Glitches Detected: {len(glitches)}")
    print(f"Clipping Detected: {'Yes' if clipping else 'No'}")
    print(f"Frequency Spikes: {freq_spikes}")

    # Transcribe audio
    transcription = transcribe_audio(file_path)
    print("Transcription:", transcription)

    # Calculate overall quality percentage
    total_checks = 5  # Number of quality checks
    good_checks = sum([
        rms > 0.01,  # RMS should be greater than threshold
        not silence_detected,  # Silence detected should be false
        snr > 20,  # SNR threshold
        transcription != "",  # Successful transcription
    ])
    
    # Add duration check (should be reasonable length, e.g., > 1 second)
    if duration > 1:
        good_checks += 1

    quality_percentage = (good_checks / total_checks) * 100

    # Determine if the overall quality is good or not
    quality_status = "Good" if quality_percentage >= 75 else "Not Good"

    # Print final quality report
    print(f"Overall Quality: {quality_status} ({quality_percentage:.2f}%)")

    # Save waveform plot as PNG
    plot_waveform(data, sample_rate, duration, channels, rms, silence_percentage, snr, glitches, clipping, freq_spikes, "audio_quality_report.png")

if __name__ == "__main__":
    # Input video and output audio files
    mp4_file = "input_video.mp4"  # Replace with your MP4 file path
    output_audio_file = "extracted_audio.wav"

    # Step 1: Extract audio from the MP4 file
    extract_audio_from_video(mp4_file, output_audio_file)

    # Step 2: Rate the audio quality
    rate_audio_quality(output_audio_file)
