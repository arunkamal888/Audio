import sys
import json
from vosk import Model, KaldiRecognizer
import wave

def transcribe_audio(model_path, audio_file):
    # Load the Vosk model from the specified path
    model = Model(model_path)
    wf = wave.open(audio_file, "rb")

    # List of numbers as words you want to recognize
    number_words = [
        "zero", "one", "two", "three", "four", "five",
        "six", "seven", "eight", "nine", "ten",
        "eleven", "twelve", "thirteen", "fourteen", "fifteen",
        "sixteen", "seventeen", "eighteen", "nineteen", "twenty",
        "thirty", "forty", "fifty", "sixty", "seventy",
        "eighty", "ninety", "hundred"
    ]

    # Convert the list to a JSON format that includes it as the "words" field
    grammar_json = json.dumps({"words": number_words})

    # Initialize the recognizer with the model, sample rate, and custom grammar
    rec = KaldiRecognizer(model, wf.getframerate(), grammar_json)

    # Read data from the file and process it through the recognizer
    results = []
    while True:
        data = wf.readframes(4000)
        if len(data) == 0:
            break
        if rec.AcceptWaveform(data):
            results.append(rec.Result())

    # Collect the final result
    results.append(rec.FinalResult())
    # Combine all recognized text fragments
    transcription = " ".join([json.loads(result)['text'] for result in results if 'text' in json.loads(result)])

    return transcription

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("Usage: python transcribe.py <model_path> <audio_file>")
        sys.exit(1)

    model_path = sys.argv[1]
    audio_file = sys.argv[2]
    transcription = transcribe_audio(model_path, audio_file)
    print(transcription)
