from moviepy.editor import VideoFileClip
import speech_recognition as sr
import numpy as np
import scipy.io.wavfile as wav
import matplotlib.pyplot as plt

def extract_audio_from_video(mp4_file, output_audio_file):
    """
    Extracts the audio from an MP4 file and saves it as a .wav file.
    """
    try:
        video = VideoFileClip(mp4_file)
        video.audio.write_audiofile(output_audio_file)
        print(f"Audio extracted to: {output_audio_file}")
    except Exception as e:
        print(f"An error occurred while extracting audio: {e}")

def analyze_audio_properties(data, sample_rate):
    """Analyze properties like duration, RMS, and channels."""
    duration = len(data) / sample_rate  # in seconds
    channels = data.shape[1] if len(data.shape) > 1 else 1  # Check if stereo or mono

    # Calculate RMS (Root Mean Square)
    rms = np.sqrt(np.mean(data**2))

    return duration, channels, rms

def detect_silence(data, threshold=0.01):
    """Detect silence in audio data."""
    silence = np.mean(np.abs(data)) < threshold
    return silence

def calculate_snr(signal, noise):
    """Calculate Signal-to-Noise Ratio (SNR)."""
    signal_power = np.mean(signal ** 2)
    noise_power = np.mean(noise ** 2)
    snr = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else float('inf')
    return snr

def plot_waveform(data, sample_rate):
    """Plot the audio waveform."""
    time = np.linspace(0., len(data) / sample_rate, num=len(data))
    plt.figure(figsize=(12, 4))
    plt.plot(time, data, label='Waveform')
    plt.title('Audio Waveform')
    plt.xlabel('Time [s]')
    plt.ylabel('Amplitude')
    plt.legend()
    plt.grid()
    plt.show()

def recognize_speech_from_audio(audio_file):
    """
    Recognizes speech from the given audio file using Google's Speech Recognition API.
    """
    recognizer = sr.Recognizer()
    try:
        with sr.AudioFile(audio_file) as source:
            audio_data = recognizer.record(source)
            print("Performing speech recognition...")
            text = recognizer.recognize_google(audio_data)
            print("Recognized text:", text)
    except sr.UnknownValueError:
        print("Speech recognition could not understand the audio")
    except sr.RequestError as e:
        print(f"Could not request results from Google Speech Recognition service; {e}")
    except Exception as e:
        print(f"An error occurred during speech recognition: {e}")

def rate_audio_quality(file_path):
    """Rate the audio quality based on various metrics."""
    # Load audio file directly within this function
    sample_rate, data = wav.read(file_path)

    # Analyze audio properties
    duration, channels, rms = analyze_audio_properties(data, sample_rate)

    # Detect silence
    silence = detect_silence(data)

    # Calculate SNR using simple method (assuming noise is a small portion of the signal)
    if len(data) > 1000:  # To avoid index errors
        snr = calculate_snr(data[:len(data)//10], data[len(data)//10:len(data)//5])  # Arbitrary split
    else:
        snr = 0

    # Print report
    print(f"\nAudio Quality Report for: {file_path}")
    print(f"Duration: {duration:.2f} seconds")
    print(f"Channels: {channels}")
    print(f"RMS: {rms:.5f}")
    print(f"Silence Detected: {'Yes' if silence else 'No'}")
    print(f"SNR: {snr:.2f} dB")

    # Evaluate quality
    quality_score = 0
    if rms > 0.01:  # Arbitrary threshold for RMS
        quality_score += 1
    if not silence:  # Good if there's no silence
        quality_score += 1
    if snr > 20:  # Arbitrary threshold for SNR
        quality_score += 1

    # Determine final quality status
    quality_status = "Good" if quality_score >= 2 else "Not Good"
    print(f"Overall Audio Quality: {quality_status}")

    # Plot waveform
    plot_waveform(data, sample_rate)

if __name__ == "__main__":
    # Input video and output audio files
    mp4_file = "input_video.mp4"  # Replace with your MP4 file path
    output_audio_file = "extracted_audio.wav"

    # Step 1: Extract audio from the MP4 file
    extract_audio_from_video(mp4_file, output_audio_file)

    # Step 2: Recognize speech from the extracted audio
    recognize_speech_from_audio(output_audio_file)

    # Step 3: Rate the audio quality
    rate_audio_quality(output_audio_file)


+++++++++++++++++++++++++++++++++++

import numpy as np
import scipy.io.wavfile as wav
import matplotlib.pyplot as plt
from moviepy.editor import VideoFileClip
import speech_recognition as sr

def extract_audio_from_video(mp4_file, output_audio_file):
    """
    Extracts the audio from an MP4 file and saves it as a .wav file.
    """
    video = VideoFileClip(mp4_file)
    video.audio.write_audiofile(output_audio_file)
    print(f"Audio extracted to: {output_audio_file}")

def analyze_audio_properties(data, sample_rate):
    """Analyze properties like duration, RMS, and channels."""
    duration = len(data) / sample_rate  # in seconds
    channels = data.shape[1] if len(data.shape) > 1 else 1  # Check if stereo or mono

    # Calculate RMS (Root Mean Square)
    rms = np.sqrt(np.mean(data**2))

    return duration, channels, rms

def detect_silence(data, threshold=0.01):
    """Detect silence in audio data."""
    silence = np.mean(np.abs(data)) < threshold
    return silence

def calculate_snr(signal, noise):
    """Calculate Signal-to-Noise Ratio (SNR)."""
    signal_power = np.mean(signal ** 2)
    noise_power = np.mean(noise ** 2)
    snr = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else float('inf')
    return snr

def plot_waveform(data, sample_rate, duration, channels, rms, silence, snr):
    """Plot the audio waveform with analysis information."""
    time = np.linspace(0., duration, num=len(data))
    
    plt.figure(figsize=(12, 6))
    plt.plot(time, data, label='Waveform')
    plt.title('Audio Waveform')
    plt.xlabel('Time [s]')
    plt.ylabel('Amplitude')
    plt.axhline(0, color='grey', linestyle='--')  # Zero amplitude line
    plt.legend()
    plt.grid()

    # Adding annotations for audio properties
    plt.text(0.1, 0.8 * np.max(data), f'Duration: {duration:.2f} s', fontsize=10)
    plt.text(0.1, 0.75 * np.max(data), f'Channels: {channels}', fontsize=10)
    plt.text(0.1, 0.7 * np.max(data), f'RMS: {rms:.5f}', fontsize=10)
    plt.text(0.1, 0.65 * np.max(data), f'Silence Detected: {"Yes" if silence else "No"}', fontsize=10)
    plt.text(0.1, 0.6 * np.max(data), f'SNR: {snr:.2f} dB', fontsize=10)

    plt.show()

def rate_audio_quality(file_path):
    """Rate the audio quality based on various metrics."""
    # Load audio file directly within this function
    sample_rate, data = wav.read(file_path)

    # Analyze audio properties
    duration, channels, rms = analyze_audio_properties(data, sample_rate)

    # Detect silence
    silence = detect_silence(data)

    # Calculate SNR using a simple method (assuming noise is a small portion of the signal)
    if len(data) > 1000:  # To avoid index errors
        snr = calculate_snr(data[:len(data)//10], data[len(data)//10:len(data)//5])  # Arbitrary split
    else:
        snr = 0

    # Print report
    print(f"Audio Quality Report for: {file_path}")
    print(f"Duration: {duration:.2f} seconds")
    print(f"Channels: {channels}")
    print(f"RMS: {rms:.5f}")
    print(f"Silence Detected: {'Yes' if silence else 'No'}")
    print(f"SNR: {snr:.2f} dB")

    # Plot waveform with detailed analysis
    plot_waveform(data, sample_rate, duration, channels, rms, silence, snr)

if __name__ == "__main__":
    # Input video and output audio files
    mp4_file = "input_video.mp4"  # Replace with your MP4 file path
    output_audio_file = "extracted_audio.wav"

    # Step 1: Extract audio from the MP4 file
    extract_audio_from_video(mp4_file, output_audio_file)

    # Step 2: Rate the audio quality
    rate_audio_quality(output_audio_file)


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

import numpy as np
import scipy.io.wavfile as wav
import matplotlib.pyplot as plt
from moviepy.editor import VideoFileClip
import speech_recognition as sr

def extract_audio_from_video(mp4_file, output_audio_file):
    """
    Extracts the audio from an MP4 file and saves it as a .wav file.
    """
    video = VideoFileClip(mp4_file)
    video.audio.write_audiofile(output_audio_file)
    print(f"Audio extracted to: {output_audio_file}")

def analyze_audio_properties(data, sample_rate):
    """Analyze properties like duration, RMS, and channels."""
    duration = len(data) / sample_rate  # in seconds
    channels = data.shape[1] if len(data.shape) > 1 else 1  # Check if stereo or mono

    # Calculate RMS (Root Mean Square)
    rms = np.sqrt(np.mean(data**2))

    return duration, channels, rms

def detect_silence(data, threshold=0.01):
    """Detect silence in audio data."""
    silence = np.mean(np.abs(data)) < threshold
    return silence

def calculate_snr(signal, noise):
    """Calculate Signal-to-Noise Ratio (SNR)."""
    signal_power = np.mean(signal ** 2)
    noise_power = np.mean(noise ** 2)
    snr = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else float('inf')
    return snr

def plot_waveform(data, sample_rate, duration, channels, rms, silence, snr):
    """Plot the audio waveform with analysis information."""
    time = np.linspace(0., duration, num=len(data))
    
    plt.figure(figsize=(12, 6))
    plt.plot(time, data, label='Waveform')
    plt.title('Audio Waveform')
    plt.xlabel('Time [s]')
    plt.ylabel('Amplitude')
    plt.axhline(0, color='grey', linestyle='--')  # Zero amplitude line
    plt.legend()
    plt.grid()

    # Adding annotations for audio properties
    plt.text(0.1, 0.8 * np.max(data), f'Duration: {duration:.2f} s', fontsize=10)
    plt.text(0.1, 0.75 * np.max(data), f'Channels: {channels}', fontsize=10)
    plt.text(0.1, 0.7 * np.max(data), f'RMS: {rms:.5f}', fontsize=10)
    plt.text(0.1, 0.65 * np.max(data), f'Silence Detected: {"Yes" if silence else "No"}', fontsize=10)
    plt.text(0.1, 0.6 * np.max(data), f'SNR: {snr:.2f} dB', fontsize=10)

    plt.show()

def transcribe_audio(audio_file):
    """
    Recognizes speech from the given audio file using Google's Speech Recognition API.
    Returns the transcribed text.
    """
    recognizer = sr.Recognizer()
    with sr.AudioFile(audio_file) as source:
        audio_data = recognizer.record(source)
        try:
            print("Performing speech recognition...")
            text = recognizer.recognize_google(audio_data)
            return text
        except sr.UnknownValueError:
            print("Speech recognition could not understand the audio")
            return ""
        except sr.RequestError:
            print("Could not request results from Google Speech Recognition service")
            return ""

def rate_audio_quality(file_path):
    """Rate the audio quality based on various metrics."""
    # Load audio file directly within this function
    sample_rate, data = wav.read(file_path)

    # Analyze audio properties
    duration, channels, rms = analyze_audio_properties(data, sample_rate)

    # Detect silence
    silence = detect_silence(data)

    # Calculate SNR using a simple method (assuming noise is a small portion of the signal)
    if len(data) > 1000:  # To avoid index errors
        snr = calculate_snr(data[:len(data)//10], data[len(data)//10:len(data)//5])  # Arbitrary split
    else:
        snr = 0

    # Print report
    print(f"Audio Quality Report for: {file_path}")
    print(f"Duration: {duration:.2f} seconds")
    print(f"Channels: {channels}")
    print(f"RMS: {rms:.5f}")
    print(f"Silence Detected: {'Yes' if silence else 'No'}")
    print(f"SNR: {snr:.2f} dB")

    # Transcribe audio
    transcription = transcribe_audio(file_path)
    print("Transcription:", transcription)

    # Calculate overall quality percentage
    total_checks = 5  # Number of quality checks
    good_checks = sum([
        rms > 0.01,  # RMS should be greater than threshold
        not silence,  # Silence detected should be false
        snr > 20,  # SNR threshold
        transcription != "",  # Successful transcription
    ])
    
    # Add duration check (should be reasonable length, e.g., > 1 second)
    if duration > 1:
        good_checks += 1

    quality_percentage = (good_checks / total_checks) * 100

    # Determine if the overall quality is good or not
    quality_status = "Good" if quality_percentage >= 75 else "Not Good"

    # Print final quality report
    print(f"Overall Quality: {quality_status} ({quality_percentage:.2f}%)")

    # Plot waveform with detailed analysis
    plot_waveform(data, sample_rate, duration, channels, rms, silence, snr)

if __name__ == "__main__":
    # Input video and output audio files
    mp4_file = "input_video.mp4"  # Replace with your MP4 file path
    output_audio_file = "extracted_audio.wav"

    # Step 1: Extract audio from the MP4 file
    extract_audio_from_video(mp4_file, output_audio_file)

    # Step 2: Rate the audio quality
    rate_audio_quality(output_audio_file)

==========================++++++++++++++++++++++++++====================================

import numpy as np
import scipy.io.wavfile as wav
import matplotlib.pyplot as plt
from moviepy.editor import VideoFileClip
import speech_recognition as sr

def extract_audio_from_video(mp4_file, output_audio_file):
    """
    Extracts the audio from an MP4 file and saves it as a .wav file.
    """
    video = VideoFileClip(mp4_file)
    video.audio.write_audiofile(output_audio_file)
    print(f"Audio extracted to: {output_audio_file}")

def analyze_audio_properties(data, sample_rate):
    """Analyze properties like duration, RMS, and channels."""
    duration = len(data) / sample_rate  # in seconds
    channels = data.shape[1] if len(data.shape) > 1 else 1  # Check if stereo or mono

    # Calculate RMS (Root Mean Square)
    rms = np.sqrt(np.mean(data**2))

    return duration, channels, rms

def detect_silence(data, threshold=0.01):
    """Detect silence in audio data."""
    silence = np.mean(np.abs(data)) < threshold
    return silence

def calculate_snr(signal, noise):
    """Calculate Signal-to-Noise Ratio (SNR)."""
    signal_power = np.mean(signal ** 2)
    noise_power = np.mean(noise ** 2)
    snr = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else float('inf')
    return snr

def plot_waveform(data, sample_rate, duration, channels, rms, silence, snr, output_file):
    """Plot the audio waveform with analysis information and save as PNG."""
    time = np.linspace(0., duration, num=len(data))
    
    plt.figure(figsize=(12, 6))
    plt.plot(time, data, label='Waveform')
    plt.title('Audio Waveform')
    plt.xlabel('Time [s]')
    plt.ylabel('Amplitude')
    plt.axhline(0, color='grey', linestyle='--')  # Zero amplitude line
    plt.legend()
    plt.grid()

    # Adding annotations for audio properties
    plt.text(0.1, 0.8 * np.max(data), f'Duration: {duration:.2f} s', fontsize=10)
    plt.text(0.1, 0.75 * np.max(data), f'Channels: {channels}', fontsize=10)
    plt.text(0.1, 0.7 * np.max(data), f'RMS: {rms:.5f}', fontsize=10)
    plt.text(0.1, 0.65 * np.max(data), f'Silence Detected: {"Yes" if silence else "No"}', fontsize=10)
    plt.text(0.1, 0.6 * np.max(data), f'SNR: {snr:.2f} dB', fontsize=10)

    # Save the figure as a PNG file
    plt.savefig(output_file)
    plt.close()  # Close the figure to free up memory

def transcribe_audio(audio_file):
    """
    Recognizes speech from the given audio file using Google's Speech Recognition API.
    Returns the transcribed text.
    """
    recognizer = sr.Recognizer()
    with sr.AudioFile(audio_file) as source:
        audio_data = recognizer.record(source)
        try:
            print("Performing speech recognition...")
            text = recognizer.recognize_google(audio_data)
            return text
        except sr.UnknownValueError:
            print("Speech recognition could not understand the audio")
            return ""
        except sr.RequestError:
            print("Could not request results from Google Speech Recognition service")
            return ""

def rate_audio_quality(file_path):
    """Rate the audio quality based on various metrics."""
    # Load audio file directly within this function
    sample_rate, data = wav.read(file_path)

    # Analyze audio properties
    duration, channels, rms = analyze_audio_properties(data, sample_rate)

    # Detect silence
    silence = detect_silence(data)

    # Calculate SNR using a simple method (assuming noise is a small portion of the signal)
    if len(data) > 1000:  # To avoid index errors
        snr = calculate_snr(data[:len(data)//10], data[len(data)//10:len(data)//5])  # Arbitrary split
    else:
        snr = 0

    # Print report
    print(f"Audio Quality Report for: {file_path}")
    print(f"Duration: {duration:.2f} seconds")
    print(f"Channels: {channels}")
    print(f"RMS: {rms:.5f}")
    print(f"Silence Detected: {'Yes' if silence else 'No'}")
    print(f"SNR: {snr:.2f} dB")

    # Transcribe audio
    transcription = transcribe_audio(file_path)
    print("Transcription:", transcription)

    # Calculate overall quality percentage
    total_checks = 5  # Number of quality checks
    good_checks = sum([
        rms > 0.01,  # RMS should be greater than threshold
        not silence,  # Silence detected should be false
        snr > 20,  # SNR threshold
        transcription != "",  # Successful transcription
    ])
    
    # Add duration check (should be reasonable length, e.g., > 1 second)
    if duration > 1:
        good_checks += 1

    quality_percentage = (good_checks / total_checks) * 100

    # Determine if the overall quality is good or not
    quality_status = "Good" if quality_percentage >= 75 else "Not Good"

    # Print final quality report
    print(f"Overall Quality: {quality_status} ({quality_percentage:.2f}%)")

    # Save waveform plot as PNG
    plot_waveform(data, sample_rate, duration, channels, rms, silence, snr, "audio_waveform.png")

if __name__ == "__main__":
    # Input video and output audio files
    mp4_file = "input_video.mp4"  # Replace with your MP4 file path
    output_audio_file = "extracted_audio.wav"

    # Step 1: Extract audio from the MP4 file
    extract_audio_from_video(mp4_file, output_audio_file)

    # Step 2: Rate the audio quality
    rate_audio_quality(output_audio_file)

pip install numpy scipy matplotlib moviepy SpeechRecognition




????????????????????????????????????????????????????

import numpy as np
import scipy.io.wavfile as wav
import matplotlib.pyplot as plt
from moviepy.editor import VideoFileClip
import speech_recognition as sr
from scipy.fftpack import fft

def extract_audio_from_video(mp4_file, output_audio_file):
    """
    Extracts the audio from an MP4 file and saves it as a .wav file.
    """
    video = VideoFileClip(mp4_file)
    video.audio.write_audiofile(output_audio_file)
    print(f"Audio extracted to: {output_audio_file}")

def analyze_audio_properties(data, sample_rate):
    """Analyze properties like duration, RMS, and channels."""
    duration = len(data) / sample_rate  # in seconds
    channels = data.shape[1] if len(data.shape) > 1 else 1  # Check if stereo or mono

    # Calculate RMS (Root Mean Square)
    rms = np.sqrt(np.mean(data**2))

    return duration, channels, rms

def detect_glitches(data, threshold=0.1):
    """Detect audio glitches based on amplitude spikes or sudden drops."""
    glitches = []
    window_size = 1024  # Small window size for quick changes detection
    for i in range(0, len(data) - window_size, window_size):
        window = data[i:i+window_size]
        max_amp = np.max(np.abs(window))
        if max_amp > threshold:
            glitches.append(i / len(data))  # Store glitch time in relative position
    return glitches

def detect_clipping(data, threshold=0.99):
    """Detect clipping when the signal amplitude reaches or exceeds max levels too often."""
    clipped_samples = np.sum(np.abs(data) >= threshold)
    clip_ratio = clipped_samples / len(data)
    return clip_ratio > 0.01  # Arbitrary threshold, can be fine-tuned

def detect_silence(data, threshold=0.01):
    """Detect silence in audio data."""
    silence = np.mean(np.abs(data)) < threshold
    return silence

def calculate_snr(signal, noise):
    """Calculate Signal-to-Noise Ratio (SNR)."""
    signal_power = np.mean(signal ** 2)
    noise_power = np.mean(noise ** 2)
    snr = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else float('inf')
    return snr

def frequency_analysis(data, sample_rate):
    """Analyze frequency spectrum to detect unusual spikes or drops."""
    N = len(data)
    yf = fft(data)
    xf = np.linspace(0.0, sample_rate / 2.0, N // 2)
    
    # Detecting abnormal spikes
    spectrum = 2.0 / N * np.abs(yf[:N // 2])
    freq_spikes = np.sum(spectrum > 1.0)  # Can fine-tune threshold for frequency spike detection
    
    return freq_spikes

def plot_waveform(data, sample_rate, duration, channels, rms, silence, snr, glitches, output_file):
    """Plot the audio waveform with analysis information and save as PNG."""
    time = np.linspace(0., duration, num=len(data))
    
    plt.figure(figsize=(12, 6))
    plt.plot(time, data, label='Waveform')
    plt.title('Audio Waveform')
    plt.xlabel('Time [s]')
    plt.ylabel('Amplitude')
    plt.axhline(0, color='grey', linestyle='--')  # Zero amplitude line
    plt.legend()
    plt.grid()

    # Adding annotations for audio properties
    plt.text(0.1, 0.8 * np.max(data), f'Duration: {duration:.2f} s', fontsize=10)
    plt.text(0.1, 0.75 * np.max(data), f'Channels: {channels}', fontsize=10)
    plt.text(0.1, 0.7 * np.max(data), f'RMS: {rms:.5f}', fontsize=10)
    plt.text(0.1, 0.65 * np.max(data), f'Silence Detected: {"Yes" if silence else "No"}', fontsize=10)
    plt.text(0.1, 0.6 * np.max(data), f'SNR: {snr:.2f} dB', fontsize=10)
    plt.text(0.1, 0.55 * np.max(data), f'Glitches Detected: {len(glitches)}', fontsize=10)

    # Save the figure as a PNG file
    plt.savefig(output_file)
    plt.close()  # Close the figure to free up memory

def rate_audio_quality(file_path):
    """Rate the audio quality based on various metrics."""
    # Load audio file directly within this function
    sample_rate, data = wav.read(file_path)

    # Analyze audio properties
    duration, channels, rms = analyze_audio_properties(data, sample_rate)

    # Detect silence
    silence = detect_silence(data)

    # Detect glitches
    glitches = detect_glitches(data)

    # Detect clipping
    clipping = detect_clipping(data)

    # Calculate SNR using a simple method (assuming noise is a small portion of the signal)
    snr = calculate_snr(data[:len(data)//10], data[len(data)//10:len(data)//5])  # Arbitrary split

    # Perform frequency analysis
    freq_spikes = frequency_analysis(data, sample_rate)

    # Print report
    print(f"Audio Quality Report for: {file_path}")
    print(f"Duration: {duration:.2f} seconds")
    print(f"Channels: {channels}")
    print(f"RMS: {rms:.5f}")
    print(f"Silence Detected: {'Yes' if silence else 'No'}")
    print(f"SNR: {snr:.2f} dB")
    print(f"Glitches Detected: {len(glitches)}")
    print(f"Clipping Detected: {'Yes' if clipping else 'No'}")
    print(f"Frequency Spikes: {freq_spikes}")

    # Transcribe audio
    transcription = transcribe_audio(file_path)
    print("Transcription:", transcription)

    # Calculate overall quality percentage
    total_checks = 6  # Number of quality checks
    good_checks = sum([
        rms > 0.01,  # RMS should be greater than threshold
        not silence,  # Silence detected should be false
        snr > 20,  # SNR threshold
        transcription != "",  # Successful transcription
        len(glitches) == 0,  # No glitches
        not clipping  # No clipping
    ])

    quality_percentage = (good_checks / total_checks) * 100

    # Determine if the overall quality is good or not
    quality_status = "Good" if quality_percentage >= 75 else "Not Good"

    # Print final quality report
    print(f"Overall Quality: {quality_status} ({quality_percentage:.2f}%)")

    # Save waveform plot as PNG
    plot_waveform(data, sample_rate, duration, channels, rms, silence, snr, glitches, "audio_waveform.png")

if __name__ == "__main__":
    # Input video and output audio files
    mp4_file = "input_video.mp4"  # Replace with your MP4 file path
    output_audio_file = "extracted_audio.wav"

    # Step 1: Extract audio from the MP4 file
    extract_audio_from_video(mp4_file, output_audio_file)


curl -v https://ssm.us-east-1.amazonaws.com

    # Step 2: Rate the audio quality
    rate_audio_quality(output_audio_file)

java -Dorg.springframework.boot.logging.LoggingSystem=none -cp /app org.springframework.boot.loader.JarLauncher
