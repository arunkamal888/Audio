import javax.sound.sampled.*;
import java.io.File;
import java.io.IOException;

public class SilenceDetection {

    public static void analyzeAudioFile(String filePath) {
        File audioFile = new File(filePath);

        try (AudioInputStream audioInputStream = AudioSystem.getAudioInputStream(audioFile)) {
            AudioFormat format = audioInputStream.getFormat();
            long frames = audioInputStream.getFrameLength();
            int frameSize = format.getFrameSize();
            float frameRate = format.getFrameRate();
            double duration = frames / frameRate;
            System.out.println("Duration: " + duration + " seconds");

            detectSilence(audioInputStream, format);
        } catch (UnsupportedAudioFileException | IOException e) {
            e.printStackTrace();
        }
    }

    private static void detectSilence(AudioInputStream audioInputStream, AudioFormat format) throws IOException {
        // Define a threshold below which a sample is considered silent
        final int SILENCE_THRESHOLD = 10;
        byte[] buffer = new byte[1024];
        int bytesRead;
        int totalBytesRead = 0;

        while ((bytesRead = audioInputStream.read(buffer)) != -1) {
            for (int i = 0; i < bytesRead; i += 2) { // 16-bit samples, each sample consists of 2 bytes
                int sample = buffer[i] + (buffer[i + 1] << 8); // Little-endian
                sample = Math.abs(sample);

                if (sample < SILENCE_THRESHOLD) {
                    double time = totalBytesRead / format.getFrameSize() / format.getFrameRate();
                    System.out.println("Silence detected at: " + time + " seconds");
                }
                totalBytesRead += 2; // Increment by 2 because we're reading 2 bytes at a time
            }
        }
    }

    public static void main(String[] args) {
        String filePath = "/path/to/your/audiofile.wav";
        analyzeAudioFile(filePath);
    }
}
